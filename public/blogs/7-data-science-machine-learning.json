{
  "id": "7",
  "slug": "data-science-machine-learning",
  "title": {
    "tr": "Veri Bilimi ve Makine Öğrenmesi Pratikleri",
    "en": "Data Science and Machine Learning Practices"
  },
  "excerpt": {
    "tr": "Veri bilimi süreçleri, makine öğrenmesi teknikleri ve production deployment pratikleri.",
    "en": "Data science processes, machine learning techniques, and production deployment practices."
  },
  "content": {
    "tr": "# Veri Bilimi ve Makine Öğrenmesi Pratikleri\n\nVeri, 21. yüzyılın petrolü olarak tanımlanıyor ve makine öğrenmesi bu değerli kaynaktan içgörü çıkarmak için en güçlü araç haline geldi. 2024 yılında, generative AI'ın patlaması, AutoML'in demokratikleşmesi ve edge AI'ın yükselişi ile veri bilimi alanı hızla evriliyor. Bu kapsamlı yazıda, modern veri bilimi süreçlerini, makine öğrenmesi tekniklerini, MLOps pratiklerini ve gerçek dünya uygulamalarını derinlemesine inceleyeceğiz.\n\n## Modern Veri Bilimi Pipeline'ı\n\nBaşarılı bir veri bilimi projesi, iyi tanımlanmış bir pipeline gerektirir. CRISP-DM (Cross-Industry Standard Process for Data Mining) metodolojisi, endüstri standardı haline gelmiş durumda. Ancak modern yaklaşımlar, bu metodolojiye continuous integration ve deployment katmanları ekliyor.\n\n**1. Problem Definition ve Business Understanding:**\nVeri bilimi projelerinin %80'i business value üretemeden sonlanıyor. Bunun temel nedeni, problem tanımının net olmaması. Spotify'ın Discover Weekly özelliği, \"kullanıcılar yeni müzik keşfetmekte zorlanıyor\" probleminden yola çıkarak, 40 milyon kullanıcıya haftalık kişiselleştirilmiş playlist sunuyor.\n\n**2. Data Collection ve Integration:**\n```python\n# Modern data pipeline with Apache Spark\nfrom pyspark.sql import SparkSession\nfrom delta import DeltaTable\nimport great_expectations as ge\n\n# Initialize Spark with Delta Lake support\nspark = SparkSession.builder \\\n    .appName(\"MLPipeline\") \\\n    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n    .getOrCreate()\n\n# Read from multiple sources\nuser_events = spark.readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n    .option(\"subscribe\", \"user-events\") \\\n    .load()\n\n# Data quality checks with Great Expectations\nge_df = ge.dataset.SparkDFDataset(user_events)\nexpectation_suite = ge_df.expect_column_values_to_not_be_null(\"user_id\")\nge_df.expect_column_values_to_be_between(\"age\", min_value=13, max_value=120)\n\n# Write to Delta Lake for ACID transactions\nuser_events.writeStream \\\n    .format(\"delta\") \\\n    .outputMode(\"append\") \\\n    .option(\"checkpointLocation\", \"/delta/events/_checkpoints\") \\\n    .start(\"/delta/events\")\n```\n\n![Data Pipeline Architecture](https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=800&q=80)\n\n## Exploratory Data Analysis (EDA) ve Feature Engineering\n\nEDA, veri bilimcilerin Sherlock Holmes'u olduğu aşamadır. Modern araçlar, bu süreci hem hızlandırıyor hem de derinleştiriyor.\n\n**Automated EDA Tools:**\n```python\n# Pandas Profiling for comprehensive EDA\nimport pandas as pd\nfrom ydata_profiling import ProfileReport\nimport sweetviz as sv\n\n# Load data\ndf = pd.read_parquet('customer_data.parquet')\n\n# Generate comprehensive report\nprofile = ProfileReport(df, \n    title=\"Customer Analysis\",\n    explorative=True,\n    dark_mode=True,\n    config_file=\"config_minimal.yaml\"\n)\nprofile.to_file(\"customer_eda.html\")\n\n# Feature engineering with Featuretools\nimport featuretools as ft\n\n# Define entities and relationships\nes = ft.EntitySet(id=\"customer_data\")\nes = es.add_dataframe(\n    dataframe_name=\"transactions\",\n    dataframe=df,\n    index=\"transaction_id\",\n    time_index=\"timestamp\"\n)\n\n# Automated feature generation\nfeature_matrix, features = ft.dfs(\n    entityset=es,\n    target_dataframe_name=\"transactions\",\n    agg_primitives=[\"sum\", \"mean\", \"std\", \"max\", \"skew\"],\n    trans_primitives=[\"day\", \"month\", \"weekday\", \"haversine\"],\n    max_depth=2\n)\n```\n\n**Advanced Visualization:**\n```python\n# Interactive visualizations with Plotly\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Create interactive dashboard\nfig = make_subplots(\n    rows=2, cols=2,\n    subplot_titles=('Distribution', 'Correlation', 'Time Series', '3D Clusters'),\n    specs=[[{'type': 'histogram'}, {'type': 'heatmap'}],\n           [{'type': 'scatter'}, {'type': 'scatter3d'}]]\n)\n\n# Add visualizations\nfig.add_trace(go.Histogram(x=df['revenue'], name='Revenue'), row=1, col=1)\nfig.add_trace(go.Heatmap(z=df.corr(), colorscale='RdBu'), row=1, col=2)\nfig.add_trace(go.Scatter(x=df['date'], y=df['sales'], mode='lines'), row=2, col=1)\nfig.add_trace(go.Scatter3d(x=df['x'], y=df['y'], z=df['z'], mode='markers'), row=2, col=2)\n\nfig.update_layout(height=800, showlegend=False)\nfig.show()\n```\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/aircAruvnKk\" frameborder=\"0\" allowfullscreen></iframe>\n\n## Modern Machine Learning Teknikleri\n\n### 1. AutoML ve Neural Architecture Search\n\nAutoML, makine öğrenmesini demokratikleştiriyor. Google'ın AutoML, H2O.ai ve Auto-sklearn gibi platformlar, model selection ve hyperparameter tuning süreçlerini otomatikleştiriyor.\n\n```python\n# AutoML with H2O\nimport h2o\nfrom h2o.automl import H2OAutoML\n\nh2o.init()\n\n# Convert to H2O frame\nhf = h2o.H2OFrame(df)\ntrain, valid, test = hf.split_frame(ratios=[0.7, 0.15], seed=42)\n\n# Run AutoML\naml = H2OAutoML(\n    max_runtime_secs=3600,\n    max_models=20,\n    balance_classes=True,\n    include_algos=['XGBoost', 'GBM', 'DRF', 'GLM', 'DeepLearning'],\n    stopping_metric='AUC',\n    sort_metric='AUC'\n)\n\naml.train(x=features, y=target, training_frame=train, validation_frame=valid)\n\n# View leaderboard\nlb = aml.leaderboard\nprint(lb.head(10))\n\n# Best model explainability\nbest_model = aml.get_best_model()\nexplainer = h2o.explain(best_model, valid)\n```\n\n### 2. Transformer Modelleri ve Transfer Learning\n\nTransformer mimarisi, NLP'nin ötesine geçerek computer vision, time series ve hatta protein folding problemlerinde kullanılıyor.\n\n```python\n# Hugging Face Transformers for multiple tasks\nfrom transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\nimport torch\n\n# Sentiment analysis with fine-tuned model\nmodel_name = \"dbmdz/bert-base-turkish-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n\n# Fine-tuning for custom task\nfrom transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=64,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"f1\",\n    greater_is_better=True,\n    fp16=True,  # Mixed precision training\n    gradient_checkpointing=True,\n    push_to_hub=True\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()\n```\n\n### 3. Graph Neural Networks (GNN)\n\nSosyal ağlar, moleküler yapılar ve recommendation sistemleri için GNN'ler kritik öneme sahip:\n\n```python\n# PyTorch Geometric for GNN\nimport torch_geometric\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nimport torch.nn.functional as F\n\nclass GNN(torch.nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(GNN, self).__init__()\n        self.conv1 = GCNConv(input_dim, hidden_dim)\n        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n        self.classifier = torch.nn.Linear(hidden_dim, output_dim)\n        self.dropout = torch.nn.Dropout(0.2)\n        \n    def forward(self, x, edge_index, batch):\n        # Graph convolutions\n        x = F.relu(self.conv1(x, edge_index))\n        x = self.dropout(x)\n        x = F.relu(self.conv2(x, edge_index))\n        x = self.dropout(x)\n        x = F.relu(self.conv3(x, edge_index))\n        \n        # Global pooling\n        x = global_mean_pool(x, batch)\n        \n        # Classification\n        x = self.classifier(x)\n        return F.log_softmax(x, dim=1)\n```\n\n![Graph Neural Networks](https://images.unsplash.com/photo-1635070041078-e363dbe005cb?w=800&q=80)\n\n## MLOps ve Production Deployment\n\nModel geliştirmek bir şey, production'da çalıştırmak bambaşka bir challenge. MLOps, DevOps prensiplerini makine öğrenmesine uyarlıyor.\n\n### 1. Model Versioning ve Experiment Tracking\n\n```python\n# MLflow for experiment tracking\nimport mlflow\nimport mlflow.sklearn\nfrom mlflow.tracking import MlflowClient\n\nmlflow.set_tracking_uri(\"http://localhost:5000\")\nmlflow.set_experiment(\"customer_churn_prediction\")\n\nwith mlflow.start_run(run_name=\"xgboost_balanced_v2\") as run:\n    # Log parameters\n    mlflow.log_params({\n        \"n_estimators\": 100,\n        \"max_depth\": 6,\n        \"learning_rate\": 0.1,\n        \"subsample\": 0.8\n    })\n    \n    # Train model\n    model = XGBClassifier(**params)\n    model.fit(X_train, y_train)\n    \n    # Log metrics\n    predictions = model.predict(X_test)\n    mlflow.log_metrics({\n        \"accuracy\": accuracy_score(y_test, predictions),\n        \"precision\": precision_score(y_test, predictions),\n        \"recall\": recall_score(y_test, predictions),\n        \"f1\": f1_score(y_test, predictions),\n        \"auc_roc\": roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n    })\n    \n    # Log model with signature\n    signature = mlflow.models.infer_signature(X_train, predictions)\n    mlflow.sklearn.log_model(\n        model, \n        \"model\",\n        signature=signature,\n        registered_model_name=\"customer_churn_classifier\"\n    )\n    \n    # Log artifacts\n    mlflow.log_artifact(\"feature_importance.png\")\n    mlflow.log_artifact(\"confusion_matrix.png\")\n```\n\n### 2. Model Serving ve API Development\n\n```python\n# FastAPI for model serving\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nimport numpy as np\nimport joblib\nfrom typing import List\nimport redis\nimport json\n\napp = FastAPI(title=\"ML Prediction API\", version=\"1.0.0\")\n\n# Redis for caching\nredis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)\n\n# Load model\nmodel = joblib.load('models/production_model.pkl')\npreprocessor = joblib.load('models/preprocessor.pkl')\n\nclass PredictionRequest(BaseModel):\n    features: List[float]\n    user_id: str\n    \nclass PredictionResponse(BaseModel):\n    prediction: float\n    probability: List[float]\n    confidence: float\n    model_version: str\n\n@app.post(\"/predict\", response_model=PredictionResponse)\nasync def predict(request: PredictionRequest):\n    # Check cache\n    cache_key = f\"prediction:{request.user_id}:{hash(str(request.features))}\"\n    cached_result = redis_client.get(cache_key)\n    \n    if cached_result:\n        return json.loads(cached_result)\n    \n    try:\n        # Preprocess\n        features = preprocessor.transform([request.features])\n        \n        # Predict\n        prediction = model.predict(features)[0]\n        probabilities = model.predict_proba(features)[0].tolist()\n        confidence = max(probabilities)\n        \n        response = PredictionResponse(\n            prediction=float(prediction),\n            probability=probabilities,\n            confidence=confidence,\n            model_version=\"v2.1.0\"\n        )\n        \n        # Cache result\n        redis_client.setex(\n            cache_key, \n            3600,  # 1 hour TTL\n            json.dumps(response.dict())\n        )\n        \n        return response\n        \n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"healthy\", \"model_loaded\": model is not None}\n```\n\n### 3. A/B Testing ve Model Monitoring\n\n```python\n# Model monitoring with Evidently\nfrom evidently import ColumnMapping\nfrom evidently.report import Report\nfrom evidently.metric_preset import DataDriftPreset, DataQualityPreset\n\n# Setup monitoring\ncolumn_mapping = ColumnMapping(\n    prediction='prediction',\n    numerical_features=numerical_cols,\n    categorical_features=categorical_cols,\n    target='actual_label'\n)\n\n# Create drift report\ndrift_report = Report(metrics=[\n    DataDriftPreset(),\n    DataQualityPreset(),\n])\n\ndrift_report.run(\n    reference_data=reference_df,\n    current_data=production_df,\n    column_mapping=column_mapping\n)\n\n# Save report\ndrift_report.save_html(\"drift_report.html\")\n\n# Alert if drift detected\nif drift_report.as_dict()[\"metrics\"][0][\"result\"][\"dataset_drift\"]:\n    send_alert(\"Model drift detected in production!\")\n```\n\n## Real-World Case Studies\n\n### 1. Netflix: Personalization at Scale\n\nNetflix'in recommendation sistemi, günlük 500 milyondan fazla streaming hour'ı analiz ediyor:\n\n- **Matrix Factorization:** User-item interactions\n- **Deep Learning:** Content understanding (video frames, audio, subtitles)\n- **Contextual Bandits:** A/B testing optimization\n- **Time Series:** Viewing pattern prediction\n\nSonuç: İzlenen içeriğin %80'i recommendation sistem önerileri.\n\n### 2. Uber: Dynamic Pricing with ML\n\nUber'in surge pricing algoritması:\n\n```python\n# Simplified surge pricing model\nclass SurgePricingModel:\n    def __init__(self):\n        self.demand_model = load_model('demand_forecast')\n        self.supply_model = load_model('driver_availability')\n        self.elasticity_model = load_model('price_elasticity')\n        \n    def calculate_surge(self, location, time):\n        # Predict demand\n        demand = self.demand_model.predict([\n            location.lat, \n            location.lon,\n            time.hour,\n            time.weekday(),\n            is_holiday(time),\n            weather_conditions(location),\n            local_events(location, time)\n        ])\n        \n        # Predict supply\n        supply = self.supply_model.predict([location, time])\n        \n        # Calculate base surge\n        surge_multiplier = max(1.0, demand / (supply + 1e-6))\n        \n        # Apply elasticity\n        optimal_surge = self.optimize_revenue(\n            surge_multiplier,\n            self.elasticity_model\n        )\n        \n        return min(optimal_surge, MAX_SURGE)  # Cap at max surge\n```\n\n### 3. DeepMind: AlphaFold Protein Structure Prediction\n\nAlphaFold, 50 yıllık protein folding problemini çözdü:\n\n- **Architecture:** Evoformer (specialized transformer)\n- **Training Data:** 170,000 protein structures\n- **Impact:** Drug discovery acceleration\n- **Open Source:** 200M+ protein predictions released\n\n## Emerging Trends ve Future Outlook\n\n### 1. Generative AI Revolution\n\n2024, Generative AI'ın enterprise adoption'ı için dönüm noktası:\n\n```python\n# LangChain for LLM applications\nfrom langchain import OpenAI, LLMChain, PromptTemplate\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.agents import create_sql_agent\n\n# SQL agent for natural language queries\nsql_agent = create_sql_agent(\n    llm=OpenAI(temperature=0),\n    db=SQLDatabase.from_uri(\"postgresql://localhost/analytics\"),\n    verbose=True\n)\n\n# Natural language to SQL\nresult = sql_agent.run(\n    \"Show me top 10 customers by revenue last quarter\"\n)\n```\n\n### 2. Federated Learning\n\nPrivacy-preserving ML training:\n\n```python\n# TensorFlow Federated example\nimport tensorflow_federated as tff\n\n# Define federated learning process\n@tff.federated_computation\ndef federated_train(model, client_data):\n    # Local training on each client\n    client_models = tff.federated_map(\n        train_on_client,\n        (tff.federated_broadcast(model), client_data)\n    )\n    \n    # Secure aggregation\n    return tff.federated_mean(client_models)\n```\n\n### 3. Quantum Machine Learning\n\nQuantum computing + ML = exponential speedup for certain problems:\n\n```python\n# Qiskit for quantum ML\nfrom qiskit import QuantumCircuit\nfrom qiskit.circuit.library import ZZFeatureMap\nfrom qiskit_machine_learning.algorithms import QSVC\n\n# Quantum Support Vector Classifier\nfeature_map = ZZFeatureMap(feature_dimension=4, reps=2)\nqsvc = QSVC(feature_map=feature_map)\nqsvc.fit(X_train, y_train)\n```\n\n## Best Practices ve Lessons Learned\n\n1. **Start Simple:** Baseline model first, complexity later\n2. **Data Quality > Model Complexity:** \"Garbage in, garbage out\"\n3. **Version Everything:** Data, code, models, configurations\n4. **Monitor Continuously:** Data drift, model performance, business metrics\n5. **Collaborate Cross-functionally:** DS + Engineering + Business\n6. **Ethical AI:** Bias detection, fairness metrics, explainability\n7. **Fail Fast:** Quick experiments, rapid iteration\n\n## Sonuç\n\nVeri bilimi ve makine öğrenmesi, dijital dönüşümün merkezinde yer alıyor. AutoML'den Generative AI'ya, Edge ML'den Quantum Computing'e kadar hızla gelişen bu alan, sürekli öğrenme ve adaptasyon gerektiriyor. Başarılı veri bilimciler ve ML mühendisleri, sadece algoritmaları değil, business context'i, engineering best practices'i ve etik değerleri de göz önünde bulundurmalı. Gelecek, veriden değer yaratabilenlerin olacak - ve bu yolculuk henüz başlıyor.",
    "en": "# Data Science and Machine Learning Practices\n\nData is described as the oil of the 21st century, and machine learning has become the most powerful tool for extracting insights from this valuable resource."
  },
  "date": "2024-01-02",
  "readTime": {
    "tr": "30 dk okuma",
    "en": "30 min read"
  },
  "category": {
    "tr": "Data Science",
    "en": "Data Science"
  },
  "tags": ["Data Science", "Machine Learning", "Python", "AI", "Deep Learning", "MLOps", "AutoML", "Neural Networks"],
  "author": {
    "name": "Deniz Kara",
    "avatar": "https://i.pravatar.cc/150?img=7",
    "bio": {
      "tr": "Veri bilimci ve ML mühendisi",
      "en": "Data scientist and ML engineer"
    }
  },
  "featured": false,
  "metaTitle": {
    "tr": "Veri Bilimi ve ML Rehberi: Modern Teknikler ve MLOps | Tech Blog",
    "en": "Data Science and ML Guide: Modern Techniques and MLOps | Tech Blog"
  },
  "metaDescription": {
    "tr": "Modern veri bilimi süreçleri, makine öğrenmesi teknikleri, AutoML, MLOps ve production deployment stratejileri hakkında kapsamlı rehber.",
    "en": "Comprehensive guide on modern data science processes, machine learning techniques, AutoML, MLOps, and production deployment strategies."
  },
  "metaImage": "https://images.unsplash.com/photo-1551288049-bebda4e38f71?w=1200&q=80",
  "references": [
    {
      "title": "Google AI Blog - AutoML",
      "url": "https://ai.googleblog.com/2024/01/automl-advances.html",
      "author": "Google AI"
    },
    {
      "title": "Papers with Code - ML Trends",
      "url": "https://paperswithcode.com/trends",
      "author": "Papers with Code"
    },
    {
      "title": "The State of AI Report 2024",
      "url": "https://www.stateof.ai/",
      "author": "Nathan Benaich & Ian Hogarth"
    },
    {
      "title": "MLOps: Continuous delivery and automation pipelines in machine learning",
      "url": "https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning",
      "author": "Google Cloud"
    },
    {
      "title": "Hugging Face Model Hub",
      "url": "https://huggingface.co/models",
      "author": "Hugging Face"
    }
  ]
}